{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "Load MNIST.\n",
    "\n",
    "Split into training (50,000), validation (10,000), and testing (10,000).\n",
    "\n",
    "Train various classifiers: Random Forest, Extra-Trees, and SVM\n",
    "\n",
    "Combine them into ensemble and attempt to get a better score than the individual classifiers - use hard and soft voting.\n",
    "\n",
    "Once you have found one - use it on the test set.\n",
    "\n",
    "How much better does it perform compared to individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (70000, 784), Y Shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# fetch MNIST\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "print(f'X Shape: {X.shape}, Y Shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X Train: (50000, 784)\n",
      "Shape Y Train: (50000,)\n",
      "Shape X Validation: (10000, 784)\n",
      "Shape Y Validation: (10000,)\n",
      "Shape X Test: (10000, 784)\n",
      "Shape Y Test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# pop off training, validation, and test set\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = X[:50000], X[50000:60000], X[60000:], y[:50000], y[50000:60000], y[60000:]\n",
    "print('Shape X Train: {}'.format(X_train.shape))\n",
    "print('Shape Y Train: {}'.format(y_train.shape))\n",
    "print('Shape X Validation: {}'.format(X_val.shape))\n",
    "print('Shape Y Validation: {}'.format(y_val.shape))\n",
    "print('Shape X Test: {}'.format(X_test.shape))\n",
    "print('Shape Y Test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale our features since we have to run an SVM classifier later\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_val_scale = scaler.transform(X_val)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate and train a random forest classifier\n",
    "rf_params = {\"n_estimators\": [600], \"max_depth\": [30,60,150], \"max_leaf_nodes\": [250,500,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=3, scoring=\"accuracy\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 1.59 s, total: 2min 8s\n",
      "Wall time: 22min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [30, 60, 150],\n",
       "                         'max_leaf_nodes': [250, 500, 1000],\n",
       "                         'n_estimators': [600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rf_grid.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=150, max_features='auto', max_leaf_nodes=1000,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of curiousity, let's check on the best params to see that we're not way off and need to re-run gridsearch\n",
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy is: 0.9639\n"
     ]
    }
   ],
   "source": [
    "y_rf_val_pred = rf_grid.predict(X_val_scale)        #<-- this predicts on the best, re-fitted model\n",
    "print(\"Random Forest Validation Accuracy is: {}\".format(accuracy_score(y_val, y_rf_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra-Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's fit the extra trees classifier\n",
    "xt_params = {\"n_estimators\": [600], \"max_depth\": [200,400], \"max_leaf_nodes\": [1000,2000]}\n",
    "xt_grid = GridSearchCV(ExtraTreesClassifier(), xt_params, cv=3, scoring=\"accuracy\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 960 ms, total: 1min 58s\n",
      "Wall time: 14min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None,\n",
       "                                            criterion='gini', max_depth=None,\n",
       "                                            max_features='auto',\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators='warn', n_jobs=None,\n",
       "                                            oob_score=False, random_state=None,\n",
       "                                            verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [200, 400],\n",
       "                         'max_leaf_nodes': [1000, 2000],\n",
       "                         'n_estimators': [600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time xt_grid.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=200, max_features='auto', max_leaf_nodes=2000,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra-Trees Validation Accuracy is: 0.9664\n"
     ]
    }
   ],
   "source": [
    "y_xt_val_pred = xt_grid.predict(X_val_scale)        #<-- this predicts on the best, re-fitted model\n",
    "print(\"Extra-Trees Validation Accuracy is: {}\".format(accuracy_score(y_val, y_xt_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train a SVM using the grid searched hyperparameters from Chap. 5 exercises\n",
    "svc_model = SVC(C=3, gamma=0.001, kernel='rbf', probability=True, decision_function_shape='ovr')\n",
    "#^ setting for \"one-vs-rest\" and getting prediction probs for compatability with other models when we combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy is: 0.9731\n"
     ]
    }
   ],
   "source": [
    "y_svc_val_pred = svc_model.predict(X_val_scale)        \n",
    "print(\"SVM Validation Accuracy is: {}\".format(accuracy_score(y_val, y_svc_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_hard = VotingClassifier(\n",
    "    estimators=[('rf',rf_grid.best_estimator_), ('xt',xt_grid.best_estimator_), ('svc',svc_model)],\n",
    "    voting='hard')\n",
    "\n",
    "ensemble_hard.fit(X_train_scale, y_train)\n",
    "ensemble_hard_val_preds = ensemble_hard.predict(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Hard Voting Validation Accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble Hard Voting Validation Accuracy: {}'.format(accuracy_score(y_val, ensemble_hard_val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_soft = VotingClassifier(\n",
    "    estimators=[('rf',rf_grid.best_estimator_), ('xt',xt_grid.best_estimator_), ('svc',svc_model)],\n",
    "    voting='soft')\n",
    "\n",
    "ensemble_soft.fit(X_train_scale, y_train)\n",
    "ensemble_soft_val_preds = ensemble_soft.predict(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Soft Voting Validation Accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble Soft Voting Validation Accuracy: {}'.format(accuracy_score(y_val, ensemble_soft_val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Hard Voting Test Set Accuracy: 0.9644\n"
     ]
    }
   ],
   "source": [
    "# now let's run our test set on the hard and soft voting ensembles\n",
    "ensemble_hard_test_preds = ensemble_hard.predict(X_test_scale)\n",
    "print('Ensemble Hard Voting Test Set Accuracy: {}'.format(accuracy_score(y_test, ensemble_hard_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Soft Voting Test Set Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "ensemble_soft_test_preds = ensemble_soft.predict(X_test_scale)\n",
    "print('Ensemble Soft Voting Test Set Accuracy: {}'.format(accuracy_score(y_test, ensemble_soft_test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the individual classifiers from last exercise on the validation set.\n",
    "\n",
    "Create new training set that is the resulting predictions of each classifier - target is still the validation set targets.\n",
    "\n",
    "Run this dataset through a new classifier.\n",
    "\n",
    "Repeat this exercise with the test set.\n",
    "\n",
    "How does it compare to the voting classifier from earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_blend = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=150, max_features='auto', max_leaf_nodes=1000,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "xt_blend = ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                     max_depth=200, max_features='auto', max_leaf_nodes=2000,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=600,\n",
    "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "\n",
    "svm_blend = SVC(C=3, gamma=0.001, kernel='rbf', probability=True, decision_function_shape='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-fit all of our best individiual models on the training data\n",
    "rf_blend.fit(X_train_scale, y_train)\n",
    "xt_blend.fit(X_train_scale, y_train)\n",
    "svm_blend.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get validation predictions for each\n",
    "rf_val_preds = rf_blend.predict(X_val_scale)\n",
    "xt_val_preds = xt_blend.predict(X_val_scale)\n",
    "svm_val_preds = svm_blend.predict(X_val_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['3', '3', '3'],\n",
       "       ['8', '8', '8'],\n",
       "       ['6', '6', '6'],\n",
       "       ...,\n",
       "       ['5', '5', '5'],\n",
       "       ['6', '6', '6'],\n",
       "       ['8', '8', '8']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.vstack((rf_val_preds, xt_val_preds, svm_val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all of our validation predictions into a single dataset\n",
    "X_blender_val_combined = np.transpose(np.vstack((rf_val_preds, xt_val_preds, svm_val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a basic Random Forest on the new features\n",
    "rf_final_blender = RandomForestClassifier(n_estimators=100)\n",
    "rf_final_blender.fit(X_blender_val_combined, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the accuracy of our combined validation results\n",
    "accuracy_score(y_val, rf_final_blender.predict(X_blender_val_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's use our trained estimators on the test set\n",
    "rf_test_preds = rf_blend.predict(X_test_scale)\n",
    "xt_test_preds = xt_blend.predict(X_test_scale)\n",
    "svm_test_preds = svm_blend.predict(X_test_scale)\n",
    "\n",
    "# combine all of our test predictions into a single dataset\n",
    "X_blender_test_combined = np.transpose(np.vstack((rf_test_preds, xt_test_preds, svm_test_preds)))\n",
    "\n",
    "# let's check the accuracy of our combined testing results\n",
    "accuracy_score(y_test, rf_final_blender.predict(X_blender_test_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^ this is better than the hard voting ensemble on the test set of 0.9644, but not soft voting\n",
    "# ensemble of 0.9741\n",
    "# it's also not as accurate as the single best component estimator (SVM: 0.9731)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
